{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3946306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from reading_splitting_dataset_functions.ipynb\n",
      "importing Jupyter notebook from network.ipynb\n",
      "importing Jupyter notebook from solver.ipynb\n",
      "importing Jupyter notebook from optim.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.Session()\n",
    "import keras\n",
    "import keras_metrics\n",
    "\n",
    "import import_ipynb\n",
    "from reading_splitting_dataset_functions import *\n",
    "from __future__ import print_function\n",
    "from network import BasicDenseFeedforwardNet\n",
    "from solver import Solver\n",
    "from functools import partial\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5315cd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length ROI: 33676\n"
     ]
    }
   ],
   "source": [
    "data_roi=open_js_file('data_preprocessed_roi.JSON')\n",
    "print('length ROI:', len(data_roi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93aeff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. ... 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "df_roi, fid_roi, v_roi, lva_roi, lha_roi = get_acceleration_fid_v_labels(data_roi)\n",
    "l_roi = labels_roi(lva_roi, lha_roi)\n",
    "print(l_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a5aa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat: 0\n",
      "Train on 26374 samples, validate on 7302 samples\n",
      "Epoch 1/30\n",
      "26374/26374 [==============================] - 3s 96us/sample - loss: 1.0243 - accuracy: 0.7292 - precision: 0.7777 - recall: 0.3888 - val_loss: 0.9937 - val_accuracy: 0.7609 - val_precision: 0.8522 - val_recall: 0.5386\n",
      "Epoch 2/30\n",
      "26374/26374 [==============================] - 2s 94us/sample - loss: 0.9145 - accuracy: 0.8423 - precision: 0.9146 - recall: 0.6621 - val_loss: 0.9538 - val_accuracy: 0.7931 - val_precision: 0.8303 - val_recall: 0.6469\n",
      "Epoch 3/30\n",
      "26374/26374 [==============================] - 2s 90us/sample - loss: 0.8816 - accuracy: 0.8719 - precision: 0.9402 - recall: 0.7243 - val_loss: 0.9375 - val_accuracy: 0.8088 - val_precision: 0.8606 - val_recall: 0.6544\n",
      "Epoch 4/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8644 - accuracy: 0.8870 - precision: 0.9346 - recall: 0.7566 - val_loss: 0.9312 - val_accuracy: 0.8111 - val_precision: 0.8342 - val_recall: 0.7168\n",
      "Epoch 5/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8495 - accuracy: 0.9012 - precision: 0.9444 - recall: 0.7945 - val_loss: 0.9225 - val_accuracy: 0.8194 - val_precision: 0.8321 - val_recall: 0.7059\n",
      "Epoch 6/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8414 - accuracy: 0.9087 - precision: 0.9352 - recall: 0.8124 - val_loss: 0.9234 - val_accuracy: 0.8170 - val_precision: 0.8340 - val_recall: 0.7299\n",
      "Epoch 7/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8338 - accuracy: 0.9159 - precision: 0.9423 - recall: 0.8147 - val_loss: 0.9084 - val_accuracy: 0.8331 - val_precision: 0.8581 - val_recall: 0.7454\n",
      "Epoch 8/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8294 - accuracy: 0.9197 - precision: 0.9395 - recall: 0.8229 - val_loss: 0.9072 - val_accuracy: 0.8366 - val_precision: 0.8606 - val_recall: 0.8185\n",
      "Epoch 9/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8245 - accuracy: 0.9233 - precision: 0.9508 - recall: 0.8337 - val_loss: 0.9010 - val_accuracy: 0.8426 - val_precision: 0.8558 - val_recall: 0.7967\n",
      "Epoch 10/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8208 - accuracy: 0.9277 - precision: 0.9454 - recall: 0.8438 - val_loss: 0.9044 - val_accuracy: 0.8365 - val_precision: 0.8658 - val_recall: 0.7790\n",
      "Epoch 11/30\n",
      "26374/26374 [==============================] - 2s 88us/sample - loss: 0.8170 - accuracy: 0.9312 - precision: 0.9487 - recall: 0.8522 - val_loss: 0.8996 - val_accuracy: 0.8410 - val_precision: 0.8548 - val_recall: 0.7861\n",
      "Epoch 12/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8156 - accuracy: 0.9321 - precision: 0.9523 - recall: 0.8492 - val_loss: 0.8965 - val_accuracy: 0.8447 - val_precision: 0.8757 - val_recall: 0.8118\n",
      "Epoch 13/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8111 - accuracy: 0.9354 - precision: 0.9507 - recall: 0.8574 - val_loss: 0.8925 - val_accuracy: 0.8488 - val_precision: 0.8497 - val_recall: 0.8247\n",
      "Epoch 14/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8109 - accuracy: 0.9359 - precision: 0.9522 - recall: 0.8616 - val_loss: 0.8998 - val_accuracy: 0.8411 - val_precision: 0.8345 - val_recall: 0.8218\n",
      "Epoch 15/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8099 - accuracy: 0.9377 - precision: 0.9505 - recall: 0.8614 - val_loss: 0.8938 - val_accuracy: 0.8462 - val_precision: 0.8756 - val_recall: 0.8037\n",
      "Epoch 16/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8065 - accuracy: 0.9410 - precision: 0.9569 - recall: 0.8640 - val_loss: 0.8959 - val_accuracy: 0.8459 - val_precision: 0.8589 - val_recall: 0.8150\n",
      "Epoch 17/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8086 - accuracy: 0.9381 - precision: 0.9515 - recall: 0.8573 - val_loss: 0.8926 - val_accuracy: 0.8480 - val_precision: 0.8762 - val_recall: 0.8129\n",
      "Epoch 18/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8044 - accuracy: 0.9416 - precision: 0.9522 - recall: 0.8686 - val_loss: 0.8914 - val_accuracy: 0.8499 - val_precision: 0.8825 - val_recall: 0.7884\n",
      "Epoch 19/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8004 - accuracy: 0.9470 - precision: 0.9682 - recall: 0.8691 - val_loss: 0.8888 - val_accuracy: 0.8541 - val_precision: 0.8689 - val_recall: 0.8219\n",
      "Epoch 20/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8019 - accuracy: 0.9441 - precision: 0.9617 - recall: 0.8698 - val_loss: 0.8879 - val_accuracy: 0.8536 - val_precision: 0.8582 - val_recall: 0.7701\n",
      "Epoch 21/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8034 - accuracy: 0.9429 - precision: 0.9501 - recall: 0.8671 - val_loss: 0.8867 - val_accuracy: 0.8554 - val_precision: 0.8712 - val_recall: 0.8122\n",
      "Epoch 22/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.8014 - accuracy: 0.9449 - precision: 0.9555 - recall: 0.8709 - val_loss: 0.8892 - val_accuracy: 0.8509 - val_precision: 0.8811 - val_recall: 0.8087\n",
      "Epoch 23/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.7991 - accuracy: 0.9475 - precision: 0.9646 - recall: 0.8781 - val_loss: 0.8996 - val_accuracy: 0.8395 - val_precision: 0.8241 - val_recall: 0.8316\n",
      "Epoch 24/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8019 - accuracy: 0.9450 - precision: 0.9466 - recall: 0.8742 - val_loss: 0.8900 - val_accuracy: 0.8514 - val_precision: 0.8418 - val_recall: 0.8045\n",
      "Epoch 25/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.7968 - accuracy: 0.9503 - precision: 0.9594 - recall: 0.8798 - val_loss: 0.8896 - val_accuracy: 0.8517 - val_precision: 0.8338 - val_recall: 0.8003\n",
      "Epoch 26/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.7970 - accuracy: 0.9481 - precision: 0.9602 - recall: 0.8800 - val_loss: 0.8917 - val_accuracy: 0.8468 - val_precision: 0.8677 - val_recall: 0.7985\n",
      "Epoch 27/30\n",
      "26374/26374 [==============================] - 2s 87us/sample - loss: 0.7977 - accuracy: 0.9479 - precision: 0.9611 - recall: 0.8744 - val_loss: 0.8878 - val_accuracy: 0.8526 - val_precision: 0.8790 - val_recall: 0.8242\n",
      "Epoch 28/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.8025 - accuracy: 0.9432 - precision: 0.9580 - recall: 0.8579 - val_loss: 0.8856 - val_accuracy: 0.8550 - val_precision: 0.8908 - val_recall: 0.8008\n",
      "Epoch 29/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.7971 - accuracy: 0.9494 - precision: 0.9607 - recall: 0.8773 - val_loss: 0.8888 - val_accuracy: 0.8532 - val_precision: 0.8554 - val_recall: 0.8070\n",
      "Epoch 30/30\n",
      "26374/26374 [==============================] - 2s 86us/sample - loss: 0.7967 - accuracy: 0.9483 - precision: 0.9526 - recall: 0.8677 - val_loss: 0.8843 - val_accuracy: 0.8584 - val_precision: 0.8713 - val_recall: 0.8205\n",
      "repeat: 1\n",
      "Train on 26892 samples, validate on 6784 samples\n",
      "Epoch 1/30\n",
      "26892/26892 [==============================] - 3s 96us/sample - loss: 1.0312 - accuracy: 0.7216 - precision: 0.7635 - recall: 0.3741 - val_loss: 0.9747 - val_accuracy: 0.7770 - val_precision: 0.7728 - val_recall: 0.5365\n",
      "Epoch 2/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.9288 - accuracy: 0.8258 - precision: 0.9058 - recall: 0.6297 - val_loss: 0.9283 - val_accuracy: 0.8210 - val_precision: 0.8699 - val_recall: 0.6738\n",
      "Epoch 3/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8959 - accuracy: 0.8576 - precision: 0.9261 - recall: 0.7189 - val_loss: 0.9063 - val_accuracy: 0.8427 - val_precision: 0.9024 - val_recall: 0.6668\n",
      "Epoch 4/30\n",
      "26892/26892 [==============================] - 2s 85us/sample - loss: 0.8765 - accuracy: 0.8759 - precision: 0.9274 - recall: 0.7490 - val_loss: 0.8906 - val_accuracy: 0.8576 - val_precision: 0.9039 - val_recall: 0.6930\n",
      "Epoch 5/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8642 - accuracy: 0.8871 - precision: 0.9281 - recall: 0.7750 - val_loss: 0.8808 - val_accuracy: 0.8681 - val_precision: 0.8901 - val_recall: 0.7723\n",
      "Epoch 6/30\n",
      "26892/26892 [==============================] - 2s 88us/sample - loss: 0.8511 - accuracy: 0.9008 - precision: 0.9367 - recall: 0.8003 - val_loss: 0.8686 - val_accuracy: 0.8785 - val_precision: 0.9015 - val_recall: 0.7819\n",
      "Epoch 7/30\n",
      "26892/26892 [==============================] - 2s 88us/sample - loss: 0.8423 - accuracy: 0.9084 - precision: 0.9320 - recall: 0.8277 - val_loss: 0.8674 - val_accuracy: 0.8809 - val_precision: 0.8964 - val_recall: 0.7776\n",
      "Epoch 8/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8375 - accuracy: 0.9119 - precision: 0.9364 - recall: 0.8301 - val_loss: 0.8603 - val_accuracy: 0.8896 - val_precision: 0.8944 - val_recall: 0.8451\n",
      "Epoch 9/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8311 - accuracy: 0.9183 - precision: 0.9402 - recall: 0.8427 - val_loss: 0.8574 - val_accuracy: 0.8881 - val_precision: 0.9386 - val_recall: 0.7869\n",
      "Epoch 10/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8270 - accuracy: 0.9202 - precision: 0.9429 - recall: 0.8515 - val_loss: 0.8540 - val_accuracy: 0.8922 - val_precision: 0.9008 - val_recall: 0.8215\n",
      "Epoch 11/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8224 - accuracy: 0.9258 - precision: 0.9469 - recall: 0.8459 - val_loss: 0.8475 - val_accuracy: 0.8974 - val_precision: 0.9134 - val_recall: 0.8254\n",
      "Epoch 12/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8223 - accuracy: 0.9252 - precision: 0.9424 - recall: 0.8528 - val_loss: 0.8471 - val_accuracy: 0.8992 - val_precision: 0.9250 - val_recall: 0.8101\n",
      "Epoch 13/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8181 - accuracy: 0.9304 - precision: 0.9450 - recall: 0.8535 - val_loss: 0.8456 - val_accuracy: 0.8986 - val_precision: 0.9093 - val_recall: 0.8361\n",
      "Epoch 14/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8147 - accuracy: 0.9323 - precision: 0.9538 - recall: 0.8640 - val_loss: 0.8521 - val_accuracy: 0.8940 - val_precision: 0.8931 - val_recall: 0.8277\n",
      "Epoch 15/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8142 - accuracy: 0.9333 - precision: 0.9498 - recall: 0.8668 - val_loss: 0.8458 - val_accuracy: 0.9005 - val_precision: 0.8864 - val_recall: 0.8471\n",
      "Epoch 16/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8118 - accuracy: 0.9360 - precision: 0.9502 - recall: 0.8620 - val_loss: 0.8440 - val_accuracy: 0.9009 - val_precision: 0.8814 - val_recall: 0.8363\n",
      "Epoch 17/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8110 - accuracy: 0.9363 - precision: 0.9557 - recall: 0.8615 - val_loss: 0.8458 - val_accuracy: 0.8974 - val_precision: 0.8893 - val_recall: 0.8350\n",
      "Epoch 18/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8078 - accuracy: 0.9391 - precision: 0.9547 - recall: 0.8702 - val_loss: 0.8407 - val_accuracy: 0.9024 - val_precision: 0.8823 - val_recall: 0.8464\n",
      "Epoch 19/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8083 - accuracy: 0.9382 - precision: 0.9507 - recall: 0.8723 - val_loss: 0.8411 - val_accuracy: 0.9015 - val_precision: 0.8893 - val_recall: 0.8557\n",
      "Epoch 20/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8076 - accuracy: 0.9389 - precision: 0.9522 - recall: 0.8702 - val_loss: 0.8434 - val_accuracy: 0.9006 - val_precision: 0.8974 - val_recall: 0.8498\n",
      "Epoch 21/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8039 - accuracy: 0.9425 - precision: 0.9551 - recall: 0.8699 - val_loss: 0.8391 - val_accuracy: 0.9068 - val_precision: 0.9185 - val_recall: 0.8335\n",
      "Epoch 22/30\n",
      "26892/26892 [==============================] - 2s 86us/sample - loss: 0.8038 - accuracy: 0.9421 - precision: 0.9543 - recall: 0.8759 - val_loss: 0.8416 - val_accuracy: 0.9027 - val_precision: 0.8799 - val_recall: 0.8467\n",
      "Epoch 23/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8036 - accuracy: 0.9425 - precision: 0.9587 - recall: 0.8746 - val_loss: 0.8428 - val_accuracy: 0.9005 - val_precision: 0.8822 - val_recall: 0.8383\n",
      "Epoch 24/30\n",
      "26892/26892 [==============================] - 2s 85us/sample - loss: 0.8019 - accuracy: 0.9449 - precision: 0.9569 - recall: 0.8768 - val_loss: 0.8440 - val_accuracy: 0.8981 - val_precision: 0.8519 - val_recall: 0.8533\n",
      "Epoch 25/30\n",
      "26892/26892 [==============================] - 2s 85us/sample - loss: 0.8020 - accuracy: 0.9434 - precision: 0.9504 - recall: 0.8799 - val_loss: 0.8386 - val_accuracy: 0.9060 - val_precision: 0.8728 - val_recall: 0.8469\n",
      "Epoch 26/30\n",
      "26892/26892 [==============================] - 2s 85us/sample - loss: 0.7995 - accuracy: 0.9459 - precision: 0.9619 - recall: 0.8804 - val_loss: 0.8386 - val_accuracy: 0.9049 - val_precision: 0.8859 - val_recall: 0.8323\n",
      "Epoch 27/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.8003 - accuracy: 0.9449 - precision: 0.9533 - recall: 0.8862 - val_loss: 0.8397 - val_accuracy: 0.9036 - val_precision: 0.8902 - val_recall: 0.8404\n",
      "Epoch 28/30\n",
      "26892/26892 [==============================] - 2s 87us/sample - loss: 0.7990 - accuracy: 0.9464 - precision: 0.9554 - recall: 0.8859 - val_loss: 0.8453 - val_accuracy: 0.8980 - val_precision: 0.8758 - val_recall: 0.8458\n",
      "Epoch 29/30\n",
      "26892/26892 [==============================] - 2s 85us/sample - loss: 0.7990 - accuracy: 0.9465 - precision: 0.9572 - recall: 0.8798 - val_loss: 0.8410 - val_accuracy: 0.9018 - val_precision: 0.8509 - val_recall: 0.8569\n",
      "Epoch 30/30\n",
      "26892/26892 [==============================] - 2s 85us/sample - loss: 0.7987 - accuracy: 0.9464 - precision: 0.9610 - recall: 0.8820 - val_loss: 0.8354 - val_accuracy: 0.9098 - val_precision: 0.8989 - val_recall: 0.8535\n",
      "repeat: 2\n",
      "Train on 26770 samples, validate on 6906 samples\n",
      "Epoch 1/30\n",
      "26770/26770 [==============================] - 3s 94us/sample - loss: 1.0503 - accuracy: 0.6990 - precision: 0.6138 - recall: 0.2926 - val_loss: 0.9385 - val_accuracy: 0.8139 - val_precision: 0.9483 - val_recall: 0.3994\n",
      "Epoch 2/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.9437 - accuracy: 0.8100 - precision: 0.8747 - recall: 0.5911 - val_loss: 0.8935 - val_accuracy: 0.8529 - val_precision: 0.9197 - val_recall: 0.6114\n",
      "Epoch 3/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.9037 - accuracy: 0.8498 - precision: 0.8996 - recall: 0.7296 - val_loss: 0.8743 - val_accuracy: 0.8740 - val_precision: 0.9534 - val_recall: 0.6943\n",
      "Epoch 4/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8828 - accuracy: 0.8705 - precision: 0.9203 - recall: 0.7613 - val_loss: 0.8621 - val_accuracy: 0.8875 - val_precision: 0.9516 - val_recall: 0.6965\n",
      "Epoch 5/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.8681 - accuracy: 0.8830 - precision: 0.9216 - recall: 0.7882 - val_loss: 0.8466 - val_accuracy: 0.9036 - val_precision: 0.9501 - val_recall: 0.7854\n",
      "Epoch 6/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.8576 - accuracy: 0.8949 - precision: 0.9296 - recall: 0.8042 - val_loss: 0.8445 - val_accuracy: 0.9040 - val_precision: 0.9532 - val_recall: 0.7575\n",
      "Epoch 7/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8495 - accuracy: 0.8997 - precision: 0.9311 - recall: 0.8093 - val_loss: 0.8386 - val_accuracy: 0.9052 - val_precision: 0.9616 - val_recall: 0.7798\n",
      "Epoch 8/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8414 - accuracy: 0.9080 - precision: 0.9362 - recall: 0.8140 - val_loss: 0.8321 - val_accuracy: 0.9141 - val_precision: 0.9422 - val_recall: 0.8091\n",
      "Epoch 9/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8373 - accuracy: 0.9114 - precision: 0.9406 - recall: 0.8306 - val_loss: 0.8291 - val_accuracy: 0.9172 - val_precision: 0.9463 - val_recall: 0.8343\n",
      "Epoch 10/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8310 - accuracy: 0.9179 - precision: 0.9410 - recall: 0.8295 - val_loss: 0.8242 - val_accuracy: 0.9202 - val_precision: 0.9605 - val_recall: 0.8128\n",
      "Epoch 11/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8296 - accuracy: 0.9182 - precision: 0.9405 - recall: 0.8289 - val_loss: 0.8261 - val_accuracy: 0.9186 - val_precision: 0.9705 - val_recall: 0.8212\n",
      "Epoch 12/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8257 - accuracy: 0.9230 - precision: 0.9453 - recall: 0.8372 - val_loss: 0.8318 - val_accuracy: 0.9146 - val_precision: 0.9535 - val_recall: 0.7885\n",
      "Epoch 13/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8254 - accuracy: 0.9216 - precision: 0.9371 - recall: 0.8321 - val_loss: 0.8280 - val_accuracy: 0.9175 - val_precision: 0.9540 - val_recall: 0.8149\n",
      "Epoch 14/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8214 - accuracy: 0.9257 - precision: 0.9496 - recall: 0.8395 - val_loss: 0.8255 - val_accuracy: 0.9199 - val_precision: 0.9446 - val_recall: 0.8426\n",
      "Epoch 15/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.8195 - accuracy: 0.9278 - precision: 0.9373 - recall: 0.8421 - val_loss: 0.8242 - val_accuracy: 0.9202 - val_precision: 0.9699 - val_recall: 0.8184\n",
      "Epoch 16/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8184 - accuracy: 0.9292 - precision: 0.9509 - recall: 0.8473 - val_loss: 0.8228 - val_accuracy: 0.9198 - val_precision: 0.9428 - val_recall: 0.8634\n",
      "Epoch 17/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8160 - accuracy: 0.9313 - precision: 0.9403 - recall: 0.8505 - val_loss: 0.8280 - val_accuracy: 0.9153 - val_precision: 0.9758 - val_recall: 0.8007\n",
      "Epoch 18/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8138 - accuracy: 0.9334 - precision: 0.9480 - recall: 0.8601 - val_loss: 0.8208 - val_accuracy: 0.9238 - val_precision: 0.9638 - val_recall: 0.8384\n",
      "Epoch 19/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8132 - accuracy: 0.9328 - precision: 0.9495 - recall: 0.8553 - val_loss: 0.8255 - val_accuracy: 0.9179 - val_precision: 0.9739 - val_recall: 0.7936\n",
      "Epoch 20/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8116 - accuracy: 0.9353 - precision: 0.9528 - recall: 0.8578 - val_loss: 0.8228 - val_accuracy: 0.9202 - val_precision: 0.9693 - val_recall: 0.8446\n",
      "Epoch 21/30\n",
      "26770/26770 [==============================] - 2s 84us/sample - loss: 0.8101 - accuracy: 0.9358 - precision: 0.9467 - recall: 0.8457 - val_loss: 0.8197 - val_accuracy: 0.9221 - val_precision: 0.9667 - val_recall: 0.8439\n",
      "Epoch 22/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8104 - accuracy: 0.9358 - precision: 0.9442 - recall: 0.8512 - val_loss: 0.8187 - val_accuracy: 0.9253 - val_precision: 0.9622 - val_recall: 0.8633\n",
      "Epoch 23/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8098 - accuracy: 0.9352 - precision: 0.9511 - recall: 0.8481 - val_loss: 0.8266 - val_accuracy: 0.9151 - val_precision: 0.9640 - val_recall: 0.8289\n",
      "Epoch 24/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8067 - accuracy: 0.9397 - precision: 0.9475 - recall: 0.8533 - val_loss: 0.8258 - val_accuracy: 0.9176 - val_precision: 0.9628 - val_recall: 0.8388\n",
      "Epoch 25/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.8067 - accuracy: 0.9386 - precision: 0.9509 - recall: 0.8651 - val_loss: 0.8234 - val_accuracy: 0.9199 - val_precision: 0.9723 - val_recall: 0.8326\n",
      "Epoch 26/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8051 - accuracy: 0.9409 - precision: 0.9508 - recall: 0.8658 - val_loss: 0.8186 - val_accuracy: 0.9251 - val_precision: 0.9587 - val_recall: 0.8362\n",
      "Epoch 27/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.8057 - accuracy: 0.9394 - precision: 0.9410 - recall: 0.8563 - val_loss: 0.8222 - val_accuracy: 0.9204 - val_precision: 0.9645 - val_recall: 0.8473\n",
      "Epoch 28/30\n",
      "26770/26770 [==============================] - 2s 83us/sample - loss: 0.8036 - accuracy: 0.9430 - precision: 0.9493 - recall: 0.8544 - val_loss: 0.8232 - val_accuracy: 0.9201 - val_precision: 0.9583 - val_recall: 0.8196\n",
      "Epoch 29/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.8028 - accuracy: 0.9428 - precision: 0.9548 - recall: 0.8679 - val_loss: 0.8190 - val_accuracy: 0.9240 - val_precision: 0.9667 - val_recall: 0.8316\n",
      "Epoch 30/30\n",
      "26770/26770 [==============================] - 2s 82us/sample - loss: 0.8024 - accuracy: 0.9431 - precision: 0.9602 - recall: 0.8638 - val_loss: 0.8223 - val_accuracy: 0.9180 - val_precision: 0.9610 - val_recall: 0.8250\n",
      "repeat: 3\n",
      "Train on 26838 samples, validate on 6838 samples\n",
      "Epoch 1/30\n",
      "26838/26838 [==============================] - 3s 93us/sample - loss: 1.0429 - accuracy: 0.7096 - precision: 0.5885 - recall: 0.2846 - val_loss: 0.9389 - val_accuracy: 0.8206 - val_precision: 0.9331 - val_recall: 0.5807\n",
      "Epoch 2/30\n",
      "26838/26838 [==============================] - 2s 82us/sample - loss: 0.9368 - accuracy: 0.8198 - precision: 0.8899 - recall: 0.6269 - val_loss: 0.8820 - val_accuracy: 0.8710 - val_precision: 0.9859 - val_recall: 0.6725\n",
      "Epoch 3/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.9013 - accuracy: 0.8545 - precision: 0.9110 - recall: 0.6930 - val_loss: 0.8681 - val_accuracy: 0.8810 - val_precision: 0.9745 - val_recall: 0.7015\n",
      "Epoch 4/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8797 - accuracy: 0.8720 - precision: 0.9167 - recall: 0.7361 - val_loss: 0.8518 - val_accuracy: 0.8989 - val_precision: 0.9834 - val_recall: 0.7658\n",
      "Epoch 5/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8674 - accuracy: 0.8830 - precision: 0.9136 - recall: 0.7576 - val_loss: 0.8383 - val_accuracy: 0.9128 - val_precision: 0.9679 - val_recall: 0.8148\n",
      "Epoch 6/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8561 - accuracy: 0.8944 - precision: 0.9105 - recall: 0.7980 - val_loss: 0.8338 - val_accuracy: 0.9175 - val_precision: 0.9769 - val_recall: 0.8167\n",
      "Epoch 7/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8470 - accuracy: 0.9016 - precision: 0.9212 - recall: 0.8176 - val_loss: 0.8301 - val_accuracy: 0.9193 - val_precision: 0.9761 - val_recall: 0.8134\n",
      "Epoch 8/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8395 - accuracy: 0.9100 - precision: 0.9278 - recall: 0.8211 - val_loss: 0.8298 - val_accuracy: 0.9187 - val_precision: 0.9810 - val_recall: 0.8225\n",
      "Epoch 9/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8318 - accuracy: 0.9171 - precision: 0.9386 - recall: 0.8433 - val_loss: 0.8266 - val_accuracy: 0.9218 - val_precision: 0.9772 - val_recall: 0.8192\n",
      "Epoch 10/30\n",
      "26838/26838 [==============================] - 2s 82us/sample - loss: 0.8274 - accuracy: 0.9219 - precision: 0.9423 - recall: 0.8400 - val_loss: 0.8203 - val_accuracy: 0.9279 - val_precision: 0.9737 - val_recall: 0.8399\n",
      "Epoch 11/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8260 - accuracy: 0.9224 - precision: 0.9359 - recall: 0.8419 - val_loss: 0.8257 - val_accuracy: 0.9218 - val_precision: 0.9640 - val_recall: 0.8340\n",
      "Epoch 12/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8230 - accuracy: 0.9245 - precision: 0.9333 - recall: 0.8544 - val_loss: 0.8239 - val_accuracy: 0.9229 - val_precision: 0.9621 - val_recall: 0.8148\n",
      "Epoch 13/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8208 - accuracy: 0.9269 - precision: 0.9462 - recall: 0.8558 - val_loss: 0.8185 - val_accuracy: 0.9272 - val_precision: 0.9643 - val_recall: 0.8357\n",
      "Epoch 14/30\n",
      "26838/26838 [==============================] - 2s 82us/sample - loss: 0.8181 - accuracy: 0.9292 - precision: 0.9387 - recall: 0.8580 - val_loss: 0.8201 - val_accuracy: 0.9272 - val_precision: 0.9803 - val_recall: 0.8140\n",
      "Epoch 15/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8168 - accuracy: 0.9303 - precision: 0.9509 - recall: 0.8598 - val_loss: 0.8182 - val_accuracy: 0.9278 - val_precision: 0.9668 - val_recall: 0.8287\n",
      "Epoch 16/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8139 - accuracy: 0.9324 - precision: 0.9373 - recall: 0.8532 - val_loss: 0.8149 - val_accuracy: 0.9314 - val_precision: 0.9777 - val_recall: 0.8421\n",
      "Epoch 17/30\n",
      "26838/26838 [==============================] - 2s 84us/sample - loss: 0.8131 - accuracy: 0.9328 - precision: 0.9503 - recall: 0.8563 - val_loss: 0.8175 - val_accuracy: 0.9285 - val_precision: 0.9774 - val_recall: 0.8312\n",
      "Epoch 18/30\n",
      "26838/26838 [==============================] - 2s 84us/sample - loss: 0.8119 - accuracy: 0.9343 - precision: 0.9478 - recall: 0.8689 - val_loss: 0.8192 - val_accuracy: 0.9269 - val_precision: 0.9772 - val_recall: 0.8185\n",
      "Epoch 19/30\n",
      "26838/26838 [==============================] - 2s 84us/sample - loss: 0.8111 - accuracy: 0.9348 - precision: 0.9434 - recall: 0.8684 - val_loss: 0.8165 - val_accuracy: 0.9300 - val_precision: 0.9755 - val_recall: 0.8320\n",
      "Epoch 20/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8083 - accuracy: 0.9383 - precision: 0.9415 - recall: 0.8628 - val_loss: 0.8179 - val_accuracy: 0.9275 - val_precision: 0.9794 - val_recall: 0.7993\n",
      "Epoch 21/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8080 - accuracy: 0.9378 - precision: 0.9436 - recall: 0.8584 - val_loss: 0.8180 - val_accuracy: 0.9264 - val_precision: 0.9588 - val_recall: 0.8359\n",
      "Epoch 22/30\n",
      "26838/26838 [==============================] - 2s 84us/sample - loss: 0.8070 - accuracy: 0.9394 - precision: 0.9437 - recall: 0.8698 - val_loss: 0.8157 - val_accuracy: 0.9282 - val_precision: 0.9594 - val_recall: 0.8357\n",
      "Epoch 23/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8057 - accuracy: 0.9412 - precision: 0.9388 - recall: 0.8765 - val_loss: 0.8162 - val_accuracy: 0.9283 - val_precision: 0.9762 - val_recall: 0.8236\n",
      "Epoch 24/30\n",
      "26838/26838 [==============================] - 2s 71us/sample - loss: 0.8038 - accuracy: 0.9418 - precision: 0.9485 - recall: 0.8758 - val_loss: 0.8162 - val_accuracy: 0.9291 - val_precision: 0.9723 - val_recall: 0.8199\n",
      "Epoch 25/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8026 - accuracy: 0.9419 - precision: 0.9478 - recall: 0.8735 - val_loss: 0.8166 - val_accuracy: 0.9280 - val_precision: 0.9598 - val_recall: 0.8368\n",
      "Epoch 26/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.8055 - accuracy: 0.9398 - precision: 0.9494 - recall: 0.8666 - val_loss: 0.8197 - val_accuracy: 0.9242 - val_precision: 0.9769 - val_recall: 0.8063\n",
      "Epoch 27/30\n",
      "26838/26838 [==============================] - 2s 84us/sample - loss: 0.8037 - accuracy: 0.9412 - precision: 0.9528 - recall: 0.8784 - val_loss: 0.8198 - val_accuracy: 0.9250 - val_precision: 0.9711 - val_recall: 0.8084\n",
      "Epoch 28/30\n",
      "26838/26838 [==============================] - 2s 84us/sample - loss: 0.8030 - accuracy: 0.9420 - precision: 0.9483 - recall: 0.8770 - val_loss: 0.8146 - val_accuracy: 0.9300 - val_precision: 0.9747 - val_recall: 0.8092\n",
      "Epoch 29/30\n",
      "26838/26838 [==============================] - 2s 84us/sample - loss: 0.8014 - accuracy: 0.9433 - precision: 0.9525 - recall: 0.8680 - val_loss: 0.8169 - val_accuracy: 0.9275 - val_precision: 0.9689 - val_recall: 0.8245\n",
      "Epoch 30/30\n",
      "26838/26838 [==============================] - 2s 83us/sample - loss: 0.7996 - accuracy: 0.9463 - precision: 0.9539 - recall: 0.8850 - val_loss: 0.8178 - val_accuracy: 0.9263 - val_precision: 0.9802 - val_recall: 0.8256\n",
      "repeat: 4\n",
      "Train on 26860 samples, validate on 6816 samples\n",
      "Epoch 1/30\n",
      "26860/26860 [==============================] - 3s 98us/sample - loss: 1.0388 - accuracy: 0.7118 - precision: 0.7215 - recall: 0.3357 - val_loss: 0.9298 - val_accuracy: 0.8270 - val_precision: 0.9877 - val_recall: 0.5393\n",
      "Epoch 2/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.9312 - accuracy: 0.8239 - precision: 0.8939 - recall: 0.6085 - val_loss: 0.8927 - val_accuracy: 0.8574 - val_precision: 0.9879 - val_recall: 0.6148\n",
      "Epoch 3/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8957 - accuracy: 0.8583 - precision: 0.9284 - recall: 0.6766 - val_loss: 0.8769 - val_accuracy: 0.8715 - val_precision: 0.9768 - val_recall: 0.6901\n",
      "Epoch 4/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8779 - accuracy: 0.8749 - precision: 0.9258 - recall: 0.7280 - val_loss: 0.8590 - val_accuracy: 0.8888 - val_precision: 0.9707 - val_recall: 0.7539\n",
      "Epoch 5/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8641 - accuracy: 0.8871 - precision: 0.9298 - recall: 0.7641 - val_loss: 0.8481 - val_accuracy: 0.8985 - val_precision: 0.9614 - val_recall: 0.8008\n",
      "Epoch 6/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8501 - accuracy: 0.9012 - precision: 0.9266 - recall: 0.7872 - val_loss: 0.8460 - val_accuracy: 0.8985 - val_precision: 0.9669 - val_recall: 0.7994\n",
      "Epoch 7/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8457 - accuracy: 0.9031 - precision: 0.9281 - recall: 0.7883 - val_loss: 0.8382 - val_accuracy: 0.9086 - val_precision: 0.9790 - val_recall: 0.8068\n",
      "Epoch 8/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8387 - accuracy: 0.9106 - precision: 0.9323 - recall: 0.8085 - val_loss: 0.8390 - val_accuracy: 0.9070 - val_precision: 0.9784 - val_recall: 0.7881\n",
      "Epoch 9/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8337 - accuracy: 0.9145 - precision: 0.9401 - recall: 0.8177 - val_loss: 0.8355 - val_accuracy: 0.9098 - val_precision: 0.9694 - val_recall: 0.8219\n",
      "Epoch 10/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8289 - accuracy: 0.9200 - precision: 0.9408 - recall: 0.8265 - val_loss: 0.8334 - val_accuracy: 0.9124 - val_precision: 0.9559 - val_recall: 0.8388\n",
      "Epoch 11/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8237 - accuracy: 0.9243 - precision: 0.9417 - recall: 0.8256 - val_loss: 0.8341 - val_accuracy: 0.9107 - val_precision: 0.9621 - val_recall: 0.8235\n",
      "Epoch 12/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8230 - accuracy: 0.9248 - precision: 0.9389 - recall: 0.8255 - val_loss: 0.8332 - val_accuracy: 0.9118 - val_precision: 0.9471 - val_recall: 0.8526\n",
      "Epoch 13/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8218 - accuracy: 0.9254 - precision: 0.9357 - recall: 0.8336 - val_loss: 0.8339 - val_accuracy: 0.9114 - val_precision: 0.9485 - val_recall: 0.8321\n",
      "Epoch 14/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8170 - accuracy: 0.9306 - precision: 0.9433 - recall: 0.8488 - val_loss: 0.8289 - val_accuracy: 0.9137 - val_precision: 0.9561 - val_recall: 0.8104\n",
      "Epoch 15/30\n",
      "26860/26860 [==============================] - 2s 83us/sample - loss: 0.8146 - accuracy: 0.9321 - precision: 0.9455 - recall: 0.8382 - val_loss: 0.8281 - val_accuracy: 0.9177 - val_precision: 0.9494 - val_recall: 0.8286\n",
      "Epoch 16/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8122 - accuracy: 0.9345 - precision: 0.9456 - recall: 0.8432 - val_loss: 0.8283 - val_accuracy: 0.9155 - val_precision: 0.9569 - val_recall: 0.8282\n",
      "Epoch 17/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8130 - accuracy: 0.9340 - precision: 0.9381 - recall: 0.8394 - val_loss: 0.8320 - val_accuracy: 0.9127 - val_precision: 0.9587 - val_recall: 0.8257\n",
      "Epoch 18/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8122 - accuracy: 0.9345 - precision: 0.9499 - recall: 0.8492 - val_loss: 0.8298 - val_accuracy: 0.9129 - val_precision: 0.9526 - val_recall: 0.8236\n",
      "Epoch 19/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8092 - accuracy: 0.9374 - precision: 0.9506 - recall: 0.8485 - val_loss: 0.8279 - val_accuracy: 0.9148 - val_precision: 0.9457 - val_recall: 0.8348\n",
      "Epoch 20/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8104 - accuracy: 0.9355 - precision: 0.9428 - recall: 0.8442 - val_loss: 0.8299 - val_accuracy: 0.9121 - val_precision: 0.9307 - val_recall: 0.8395\n",
      "Epoch 21/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8073 - accuracy: 0.9393 - precision: 0.9484 - recall: 0.8410 - val_loss: 0.8303 - val_accuracy: 0.9121 - val_precision: 0.9379 - val_recall: 0.8422\n",
      "Epoch 22/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8055 - accuracy: 0.9402 - precision: 0.9562 - recall: 0.8537 - val_loss: 0.8286 - val_accuracy: 0.9145 - val_precision: 0.9415 - val_recall: 0.8447\n",
      "Epoch 23/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8041 - accuracy: 0.9422 - precision: 0.9518 - recall: 0.8563 - val_loss: 0.8305 - val_accuracy: 0.9123 - val_precision: 0.9381 - val_recall: 0.8535\n",
      "Epoch 24/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8050 - accuracy: 0.9407 - precision: 0.9416 - recall: 0.8480 - val_loss: 0.8323 - val_accuracy: 0.9087 - val_precision: 0.9244 - val_recall: 0.8337\n",
      "Epoch 25/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8027 - accuracy: 0.9434 - precision: 0.9509 - recall: 0.8526 - val_loss: 0.8247 - val_accuracy: 0.9190 - val_precision: 0.9409 - val_recall: 0.8487\n",
      "Epoch 26/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8021 - accuracy: 0.9441 - precision: 0.9467 - recall: 0.8571 - val_loss: 0.8242 - val_accuracy: 0.9202 - val_precision: 0.9502 - val_recall: 0.8507\n",
      "Epoch 27/30\n",
      "26860/26860 [==============================] - 2s 84us/sample - loss: 0.8021 - accuracy: 0.9431 - precision: 0.9555 - recall: 0.8544 - val_loss: 0.8256 - val_accuracy: 0.9167 - val_precision: 0.9414 - val_recall: 0.8519\n",
      "Epoch 28/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8024 - accuracy: 0.9433 - precision: 0.9477 - recall: 0.8470 - val_loss: 0.8261 - val_accuracy: 0.9158 - val_precision: 0.9492 - val_recall: 0.8467\n",
      "Epoch 29/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8014 - accuracy: 0.9439 - precision: 0.9486 - recall: 0.8510 - val_loss: 0.8274 - val_accuracy: 0.9161 - val_precision: 0.9423 - val_recall: 0.8332\n",
      "Epoch 30/30\n",
      "26860/26860 [==============================] - 2s 85us/sample - loss: 0.8006 - accuracy: 0.9449 - precision: 0.9537 - recall: 0.8621 - val_loss: 0.8260 - val_accuracy: 0.9174 - val_precision: 0.9395 - val_recall: 0.8500\n",
      "Test loss:  [0.88428045 0.83540473 0.82225837 0.81776746 0.82602617]\n",
      "Training loss:  [0.79672557 0.79874786 0.80243154 0.79962575 0.80059661]\n",
      "Test accuracy:  [0.85839498 0.90978771 0.9180423  0.92629427 0.91740024]\n",
      "Training accuracy:  [0.94828242 0.94641531 0.94310796 0.94627023 0.94493669]\n",
      "Mean of test accuracy:  0.9059839010238647 Variance of test accuracy:  0.000593484637350059\n",
      "Mean of training accuracy:  0.9458025217056274 Variance of training accuracy:  2.9508918905207796e-06\n"
     ]
    }
   ],
   "source": [
    "#def run experiment(repeats = 5):\n",
    "repeats = 5\n",
    "test_loss = np.zeros(repeats)\n",
    "test_acc = np.zeros(repeats)\n",
    "training_loss = np.zeros(repeats)\n",
    "training_acc = np.zeros(repeats)\n",
    "before = []\n",
    "for j in range(repeats):\n",
    "    print('repeat:', j)\n",
    "    x_train, y_train, x_test, y_test, before=train_test_split_cross_validation(fid_roi, df_roi, l_roi, before)\n",
    "    x_train, y_train, x_test, y_test = bring_in_right_shape_self(x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='tanh'),\n",
    "        tf.keras.layers.GaussianDropout(0.5),\n",
    "        #tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    opt = Adam(.0010)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss=loss_fn, optimizer=opt, metrics=[\"accuracy\", keras_metrics.precision(), keras_metrics.recall()])\n",
    "    number_epochs=30\n",
    "    H = model.fit(x_train, y_train, batch_size=128, validation_data=(x_test, y_test), epochs=number_epochs)\n",
    "    \n",
    "    test_loss[j] = H.history[\"val_loss\"][number_epochs-1]\n",
    "    test_acc[j] = H.history[\"val_accuracy\"][number_epochs-1]\n",
    "\n",
    "    training_loss[j] = H.history[\"loss\"][number_epochs-1]\n",
    "    training_acc[j] = H.history[\"accuracy\"][number_epochs-1]\n",
    "    \n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Training loss: ', training_loss)\n",
    "print('Test accuracy: ', test_acc)\n",
    "print('Training accuracy: ', training_acc)\n",
    "print('Mean of test accuracy: ', np.mean(test_acc), 'Variance of test accuracy: ', np.var(test_acc))\n",
    "print('Mean of training accuracy: ', np.mean(training_acc), 'Variance of training accuracy: ', np.var(training_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f7b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9dc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
